---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---
I am Yu Liu (åˆ˜æ¯“), a final-year M.S. candidate in the [School of Intelligent Science and Technology](http://hias.ucas.ac.cn/znkxyjs/index.htm), [Hangzhou Institute for Advanced Study (HIAS)](http://hias.ucas.ac.cn/), [University of Chinese Academy of Sciences (UCAS)](https://www.ucas.edu.cn/).

My research interests include LLM-based agents, multimodal reasoning, cross-modal alignment, and affective computing.

I am very fortunate to be advised by [Prof. Taihao Li](https://people.ucas.ac.cn/~0070909) and [Dr. Leyuan Qu](https://people.ucas.edu.cn/~leyuanqu).

You can find my CV here: [Yu Liu's Curriculum Vitae](../assets/Yu_Liu_CV.pdf) (Updated: Oct 24, 2025).

<!-- [Email](mailto:liuyu233@mails.ucas.ac.cn) / [Github](https://github.com/YultheConkor) / [LinkedIn](https://www.linkedin.com/in/yu-liu-1b8004238/) -->

<section id="research-highlights">
  <h1>Research Highlights</h1>
  <h2>Affective & Social AI</h2>
  <p><em>Research Highlights â€” Core: Multimodal Empathetic Dialogue Agent</em><br>
  <small>Role: Lead for multimodal fusion across textâ€“audioâ€“visual streams.</small><br>
  <small>Agent pipeline: Perception â†’ Dialogue Understanding â†’ Expression</small></p>

  <ul>
    <li>
      <strong>GRACE for Multimodal Facial Emotion Recognition</strong>
      [IEEE Transactions on Affective Computing <em>under review</em>, 
      <a href="https://arxiv.org/abs/2507.11892" target="_blank" rel="noopener">arXiv</a>] ðŸŒŸ:
      <br>
      Introduces <em>GRACE</em> for dynamic facial emotion recognition by aligning refined linguistic cues with salient facial dynamics; achieves SOTA on DFEW, FERV39k, and MAFW.
      <em>Agent module: instant emotion perception for the dialogue agent.</em>
    </li>

    <li>
      <strong>Centering Emotion Hotspots</strong>
      [under review; <a href="https://arxiv.org/abs/2510.08606" target="_blank" rel="noopener">arXiv (Oct 2025)</a>] ðŸŒŸ:
      <br>
      Extends GRACE from frame-level signals to conversation-level tracking by centering multimodal hotspots and fusing them with dialogue context, improving stability and generalization across turns.
      <em>Agent module: dialogue-level emotion understanding.</em>
    </li>

    <li>
      <strong>Think-Before-Draw</strong>
      [Pattern Recognition <em>under review</em> Â· 
      <a href="https://arxiv.org/abs/2507.12761" target="_blank" rel="noopener">arXiv</a>]:
      <br>
      A two-stage framework for disentangled, controllable talking-head synthesis. Designed the multimodal fusion module integrating audioâ€“textâ€“visual cues to preserve identity and sharpen affect control.
      <em>Agent module: controllable affective expression for responses.</em>
    </li>
  </ul>

  <h2>Digital Therapeutics</h2>

  
  <p><strong>Zhejiang Vanguard Project: Digital Therapeutics for Depression Detection</strong><br>
  <em>Research Highlight: Unified <strong>visual biomarker extraction</strong> with <strong>LLM-augmented questionnaire semantics</strong> via multimodal fusion for depression screening under privacy/low-resource constraints; <strong>incubated HOPE</strong> for subject-level estimation.</em> <br>
  <small>Role: Led <strong>multimodal fusion</strong> (video/audio/text); built the visual-biomarker pipeline; drove cross-module integration aligned to subject-level decisions.</small>
  </p>

<ul>
  <li>
    <strong>HOPE: Hierarchical Fusion for Optimized and Personality-Aware Estimation of Depression</strong>
    [<a href="https://doi.org/10.1145/3746027.3762063" target="_blank" rel="noopener">ACM MM â€™25 Â· MPDD Challenge (Young Track) Â· DOI</a> Â·
     <a href="https://github.com/YultheConkor/HOPE" target="_blank" rel="noopener">GitHub</a>] ðŸŒŸ
    <br>
    Subject-level depression detection under privacy constraints via <strong>hierarchical multimodal fusion</strong> (audioâ€“video with personalized textual cues) and cross-task/sample <strong>consistency</strong>â€”<strong>1st place</strong> in the MPDD Young Track.<br>
    <em>Role:</em> <strong>Developed the consistency-aware subject-level fusion strategy</strong>; led the writing; completed final code integration and open-source release preparation.
  </li>
</ul>

  <h2>Earlier Work: Aviation Analytics</h2>
  <ul>
    <li>
      <strong>Risk Propagation on Flight Networks</strong>
      [<a href="https://doi.org/10.16097/j.cnki.1009-6744.2020.01.001" target="_blank" rel="noopener">Journal of Transportation Systems Engineering (2020) Â· DOI</a> 2023 Frontrunner 5000 Top Article]ðŸŒŸ:
      Introduced Spearman correlation + SIR dynamics into airline operational risk management, yielding deployable complex-network propagation analysis.
    </li>
  </ul>
</section>

<section id="education">
  <h1>Education</h1>
  <ul>
    <li>
      University of Chinese Academy of Sciences â€” <strong>M.S. in Artificial Intelligence</strong>, Hangzhou Institute for Advanced Study (GPA 3.76/4.00),
      <em>Sep 2023 â€“ Jun 2026 (expected)</em>.
    </li>
    <li>
      Civil Aviation University of China â€” <strong>B.S. in Transportation</strong> (GPA 3.36/4.00),
      <em>Sep 2015 â€“ Jun 2019</em>.
    </li>
  </ul>
</section>

<section id="work-experience">
  <h1>Work Experience</h1>

  <h2>China Southern Airlines â€” Data Analyst, Airlines Operations Center <span style="font-weight:normal;">(Sep 2019 â€“ May 2023)</span></h2>
  <ul>
    <li>
      Built Python/MySQL analytics and monitoring; automated Tableau/QuickBI reporting, reducing manual report time by <strong>&gt;70%</strong> and enabling shared data services across departments.
    </li>
    <li>
      Led a Django+SQL delay/fault analytics platform, cutting report generation time by <strong>~85%</strong> and supporting operational safety and decision-making.
    </li>
  </ul>

  <h2>Hangzhou Institute for Advanced Study, UCAS â€” Lab Coordinator &amp; Administrator <span style="font-weight:normal;">(Sep 2024 â€“ Present)</span></h2>
  <ul>
    <li>
      Managed onboarding, event organization, and <strong>GPU resource</strong> scheduling; oversaw equipment procurement and reimbursement workflows to keep projects moving.
    </li>
  </ul>
</section>

<section id="professional-service">
  <h1>Professional Service</h1>
  <ul>
    <li><strong>Journal Reviewer</strong>: <em>Pattern Recognition</em> (Elsevier), <em>2025â€“present</em>.</li>
  </ul>
</section>